# Abstract

- 之前在医学图像分割领域，基于CNN和Transformer的模型得到了广泛的探索。CNN在远程建模能力方面能力受到限制，但Transformer计算复杂性大
- 以Mamba为例的状态空间模型(SSMs)作为一种很有前途的方法出现了。它们不仅在远程相互作用建模方面表现优异，而且保持了线性计算复杂度
- 我们提出了VM-UNet，引入了视觉状态空间(VSS)块作为基础块来捕获广泛的上下文信息，并构造了一个非对称的编码器-解码器结构
- 我们在ISIC17, ISIC18和Synapse数据集上进行了全面的实验，结果表明VM-UNet在医学图像分割任务中具有竞争力。

# Introduction

- 概述了自动化医学图像分割技术的发展，特别是基于CNN和Transformer模型在提高诊断效率方面的进展。UNet模型因其结构简单和强大的可扩展性而受到推崇，而TransUnet则首次引入了ViT进行特征提取，展示了全局信息获取的显著能力。
- 尽管如此，CNN模型在捕获长距离信息方面受到局限，而Transformer模型则因其自注意力机制的二次复杂度而导致计算负担重。
- 最近，状态空间模型(SSM)因其在建立长距离依赖和维持线性计算复杂度方面的优势而受到关注。本文提出了一种全新的纯SSM模型——Vision Mamba UNet (VM-UNet)，旨在探索SSM模型在医学图像分割中的潜力。

# Method

![image-20240219131337375](https://pj-typora.oss-cn-shanghai.aliyuncs.com/image-20240219131337375.png)

## Vision Mamba UNet (VM-UNet)

VM-UNet采用非对称设计，包括Patch Embedding层、编码器、解码器、Final Projection层和跳跃连接。Patch Embedding层将输入图像划分为4×4大小的非重叠块，然后通过编码器进行特征提取，编码器由四个阶段组成，前三个阶段末尾通过patch merging操作减少特征的高度和宽度，同时增加通道数。解码器亦由四个阶段组成，使用patch expanding操作来减少特征通道数并增加特征的高度和宽度。跳跃连接通过简单的加法操作，不引入额外参数。

## VSS block

VSS块是VM-UNet的核心组件，包含两个分支：第一个分支通过线性层和激活函数处理输入；第二个分支在输入通过线性层、深度可分离卷积和激活函数后，送入2D-Selective-Scan (SS2D)模块进行进一步的特征提取。SS2D模块包括扫描展开操作、S6块和扫描合并操作，能够从多个方向彻底扫描信息，捕捉多样化的特征。通过调整SSM的参数，S6块在S4的基础上引入选择性机制，使模型能够区分和保留相关信息。

## Loss function

VM-UNet使用最基础的二元交叉熵和Dice损失（BceDice loss）以及交叉熵和Dice损失（CeDice loss）作为二分类和多分类分割任务的损失函数。这些损失函数的组合通过调整λ参数进行加权，旨在验证纯SSM模型在医学图像分割任务中的应用潜力。



# 代码

在您提供的文件中，定义了`vmunet.py`和`vmamba.py`，其中包含了构建Vision Mamba UNet (VM-UNet) 模型的类。这个模型是一个深度学习网络，用于图像分割任务，特别是在医学图像分析领域。以下是每个类的功能和它们在模型中的顺序：

1. **PatchEmbed2D**: 这个类用于将输入图像转换成一个嵌入的特征映射。它通过将图像划分成小块(patch)并对每个块应用一个卷积操作实现这一点。生成的特征映射将作为模型深层次结构的输入。

2. **PatchMerging2D**: 这个类在编码器的不同阶段中用来减少空间分辨率，同时增加特征维度。它通过合并相邻的patch和应用线性变换来实现这一点。

3. **SS2D**: 这个类实现了状态空间模型（SSM），它是模型中的自注意力机制的替代品。SS2D处理输入特征并能够捕捉长距离依赖关系。

4. **VSSBlock**: 这是模型的构建块，包含自注意力（SS2D）模块和残差连接。它对输入特征进行处理，并将处理后的特征与原始输入相加以创建残差。

5. **VSSLayer 和 VSSLayer_up**: 这两个类定义了编码器和解码器中的层，分别用于降采样和升采样特征映射。每个层由一系列的`VSSBlock`构成，可以通过深度(depth)参数来控制每个层中`VSSBlock`的数量。

6. **PatchExpand2D 和 Final_PatchExpand2D**: 与`PatchMerging2D`类似，这两个类在解码器中用于将特征映射的空间分辨率升高。`Final_PatchExpand2D`通常在解码器的最后阶段使用，将特征映射的空间维度恢复到与输入图像相同的大小。

7. **VSSM**: 这是整个模型的主类，它集成了上述所有组件。首先，通过`PatchEmbed2D`对输入图像进行嵌入，然后通过一系列的`VSSLayer`对特征进行编码，接着通过`VSSLayer_up`对特征进行解码，最后通过`Final_PatchExpand2D`和一个卷积层(`final_conv`)生成最终的分割图。

模型处理流程通常如下：

- 输入图像首先通过`PatchEmbed2D`转换为特征映射。
- 接下来，特征映射通过一系列`VSSLayer`进行编码。
- 编码后的特征映射通过一系列`VSSLayer_up`进行解码。
- 最后，解码后的特征通过`Final_PatchExpand2D`和`final_conv`生成最终的输出。

在这个过程中，`DropPath`、`LayerNorm`和其他一些组件被用来正则化和标准化网络中的特征，以改进训练过程和模型的泛化能力。整个模型的架构设计用于有效地处理大型的图像数据集，并且具有捕获图像中复杂模式的能力。
