# 摘要

## MLKA

卷积神经网络（ConvNets）通过利用更大的感受野，可以在高层次任务中与Transformers竞争。为了释放卷积神经网络在超分辨率任务中的潜力，我们提出了一种多尺度注意力网络（MAN），通过将经典的多尺度机制与新兴的大核注意力相结合。具体来说，我们提出了多尺度大核注意力（MLKA）和门控空间注意单元（GSAU）。通过MLKA，我们对大核注意进行了多尺度和门控方案的改进，以在不同粒度水平上获得丰富的注意力图，从而聚合全局和局部信息，避免可能的分块伪影。在GSAU中，我们整合了门控机制和空间注意力，去除了不必要的线性层，并聚合了有信息量的空间上下文。为了验证我们设计的有效性，我们通过简单堆叠不同数量的MLKA和GSAU来评估具有不同复杂度的MAN。实验结果表明，我们的MAN可以与SwinIR媲美，并在先进性能与计算复杂度之间实现了不同的权衡。

## D-LKA

医学图像分割领域在使用Transformer模型后取得了显著进展，这些模型擅长捕捉远距离上下文和全局上下文信息。然而，这些模型的计算需求与token数量的平方成正比，限制了它们的深度和分辨率能力。目前大多数方法都是逐片处理三维体数据（称为伪三维），因此错失了关键的切片间信息，导致模型整体性能下降。为了解决这些挑战，我们引入了可变形大核注意力（D-LKA Attention）的概念，这是一种精简的注意力机制，采用大卷积核来全面捕捉体数据的上下文信息。该机制的感受野与自注意力相当，同时避免了计算开销。此外，我们提出的注意力机制利用可变形卷积灵活调整采样网格，使模型能够适应不同的数据模式。我们设计了D-LKA Attention的2D和3D版本，其中3D版本在理解跨深度数据方面表现突出。以上组件共同构成了我们新颖的层次化视觉Transformer架构——D-LKA Net。在流行的医学图像分割数据集（如Synapse、NIH胰腺和皮肤病变）上，我们的模型相较于领先方法展现了更优异的性能。

## M2SNet

摘要——准确的医学图像分割对于早期医疗诊断至关重要。大多数现有方法基于U型结构，并在解码器中逐步使用逐元素加法或拼接操作来融合不同级别的特征。然而，这两种操作容易产生大量冗余信息，削弱了不同级别特征之间的互补性，导致病灶定位不准确和边缘模糊。为了解决这一挑战，我们提出了一种通用的多尺度减法网络（M2SNet），用于完成医学图像的多样化分割。具体来说，我们首先设计了一个基本的减法单元（SU），用于生成编码器中相邻层之间的差异特征。接下来，我们将单尺度SU扩展为层内多尺度SU，它可以为解码器提供像素级和结构级的差异信息。然后，我们在不同层次上以金字塔形式配备多尺度SU，并采用不同的感受野，从而实现层间多尺度特征聚合，获得丰富的多尺度差异信息。此外，我们构建了一个训练无关的网络“LossNet”，从底层到顶层全面监督任务相关的特征，这推动了我们的多尺度减法网络同时捕捉细节和结构线索。无需复杂的附加设计，我们的方法在四种不同医学图像分割任务的十一组数据集上（包括彩色结肠镜成像、超声成像、计算机断层扫描（CT）、光学相干断层扫描（OCT））的不同评估指标中，优于大多数最新的先进方法。

## DB-SAM

最近，**Segment Anything Model (SAM)** 在多种下游分割任务中展示了出色的分割能力。然而，当直接应用SAM到通用医学图像分割时，因自然图像和2D/3D医学数据之间存在领域差异，表现出现了显著的落差。为解决这一问题，本文提出了一种双分支改进的SAM框架，称为**DB-SAM**，旨在有效弥合这一领域差异。

DB-SAM框架包含两条并行的分支：**ViT分支**和**卷积分支**。在ViT分支中，我们在每个冻结的注意力模块后添加了一个可学习的通道注意力模块，以捕获领域特定的局部特征。与此同时，卷积分支使用轻量级卷积模块，从输入的医学图像中提取领域特定的浅层特征。为实现跨分支特征融合，我们设计了**双向交叉注意力模块**和**ViT卷积融合模块**，动态结合两条分支中的不同信息，用于掩码解码器。

在大规模医学图像数据集上，针对多种3D和2D医学分割任务的广泛实验表明，我们提出的方法表现出显著优势。在21项3D医学图像分割任务中，我们的DB-SAM与文献中的近期医学SAM适配器相比，绝对增益达到了**8.8%**。



## 自己的

医学图像分割在临床诊断中起着至关重要的作用。现有的SAM2-UNet模型是一种在多种图像分割任务中表现优异的通用框架，通过采用Hiera骨干网络作为编码器，并结合经典的U型解码器设计，展现出强大的分割能力。本研究将SAM2-UNet应用于医学图像分割任务，以进一步提升其在该领域的性能。然而，现有的分割模型在处理边缘信息和细节捕捉方面仍存在局限性，导致分割精度不足。为进一步提升模型的性能，本研究对SAM2-UNet进行了改进，引入了新的组合模块（CombinedModule）。该模块结合了多尺度大卷积核注意力（MLKA）和边缘增强注意力模块（ESAM），在增强细节分割能力的同时，能够更加有效地捕捉和建模上下文信息，特别是更加关注边缘细节。此外，我们对模型中的感受野块（RFB）进行了改进，引入了多维度的注意力机制，以增强全局与局部特征的表达能力，从而进一步提升模型的分割精度。实验结果表明，经过改进的模型在多个医学图像分割任务中均取得了优异的表现，尤其在细节分割和边缘检测方面显著提升。该方法为医学图像处理提供了新的优化思路，具有广泛的应用前景。



医学图像分割在临床诊断中起着至关重要的作用。尽管现有的SAM2-UNet在多种图像分割任务中表现优异，但在处理细节捕捉和边缘信息方面仍存在局限性，导致分割精度不足。为此，我们提出了一种改 进的医学图像分割框架，结合了多尺度大卷积核注意力和边缘增强注意力模块，以增强模型在细节和上下文信息建模方面的能力，特别是对边缘细节的关注。此外，我们对感受野块（RFB）进行了改进，引入了多维度的注意力机制，以进一步提升全局与局部特征的表达能力。实验结果表明，改进后的模型在多个医学图像分割任务中取得了优异的表现，尤其在边缘检测和细节分割方面显著提升。该方法为医学图像处理提供了新的优化思路，具有广泛的应用前景。





# 1 Introduction

医学图像分割在疾病诊断和手术规划等多种临床应用中起着至关重要的作用。近年来，深度学习的进展显著提高了医学图像分割模型的性能。然而，大多数现有方法是任务特定的[32, 8, 9]，这意味着它们通常专注于使用特定类型医疗设备获取的数据集进行特定分割任务。因此，这些模型在处理多样化的分割任务时表现出有限的泛化能力，特别是当涉及不同类型的成像设备时。

最近推出的Segment Anything Model（SAM）[18]作为一种任务无关的分割模型，可以在自然图像上执行通用分割任务。SAM虽然在大规模数据集上表现出良好的泛化能力，但在直接应用于医学图像分割时表现出一些缺点，特别是在捕捉细微结构和复杂特征方面存在不足。这些缺点限制了其在医学图像中的分割精度。

为了解决这一问题，我们提出了一种新型模型，称为**MSA-SAMNet**。该模型结合了多种注意力模块，包括多尺度大核注意力（MLKA）模块、边缘增强注意力模块（ESAM）和感受野块（RFB）。MLKA模块通过跨多个尺度处理特征，有效捕捉全局和局部信息，从而增强了模型对医学图像中不同细节级别的适应性。而ESAM模块旨在加强边缘信息，显著提高解剖结构边缘的分割准确性。此外，RFB模块通过多分支卷积处理优化特征选择和融合，增强了模型从不同感受野中提取相关特征的能力。

提出的MSA-SAMNet将这些先进模块与SAM2结合，形成了一个强大的医学图像分割混合架构。通过利用每个组件的优势，MSA-SAMNet在多个息肉分割数据集（包括Kvasir-SEG、CVC-ClinicDB、CVC-ColonDB、CVC-300和ETIS）上表现出一致的性能提升。实验结果表明，MSA-SAMNet在复杂场景和边缘精度保持方面实现了最先进的分割精度，显著优于现有方法。

**贡献**：

1. 我们提出了一种新型的医学图像分割模型MSA-SAMNet，通过结合SAM与多种先进模块，实现了对医学图像的高精度分割。
2. 我们设计了多尺度大核注意力（MLKA）模块，用于增强模型对不同尺度下细节信息的捕捉能力，从而改善对复杂医学图像的分割效果。
3. 我们引入了边缘增强注意力模块（ESAM），有效提升了模型在边缘区域的分割精度，特别是在解剖结构的细微边缘部分。
4. 我们开发了感受野块（RFB），通过多分支卷积结构优化特征提取和融合，使模型能够从不同感受野中提取更丰富的特征。
5. 在多个息肉分割数据集上的实验表明，我们的MSA-SAMNet在复杂场景和保持边缘精度方面显著优于现有方法，证明了其在医学图像分割任务中的有效性。





# 2 Related Work

近年来，深度学习在医学图像分割领域取得了巨大的进展，尤其是基于卷积神经网络（CNN）的方法，如U-Net、全卷积网络（FCN）、DeepLab和SegCaps等。CNN在医学图像分割中的应用得益于其强大的特征提取能力，能够捕获图像中的丰富细节和复杂特征，从而在不同类型的医学影像上表现出色。例如，DeepLab系列通过引入空洞卷积（Atrous Convolution）扩大了感受野，有效捕获全局信息，处理复杂背景，而SegCaps利用胶囊网络在特征表达方面的优势，进一步提升了对复杂形态和空间关系的表达能力。这些模型通过端到端的学习，大大提高了医学图像分割的精度和效率。尽管如此，传统的CNN架构通常只关注局部特征，难以充分捕获全局上下文信息，这在处理复杂的医学图像时表现出一定的局限性。例如，在存在多个病灶或背景复杂的情况下，仅依靠局部特征难以实现准确分割。此外，CNN的卷积操作天然具有局部感受野，在跨越长距离的依赖关系时存在不足，难以对全局信息进行有效建模。

为了解决这些问题，U形网络架构（如U-Net）被广泛应用于医学图像分割中。U-Net通过对称的编码器-解码器结构和跳跃连接实现了不同尺度特征的融合，有效保留了高分辨率的空间信息，从而在复杂图像中表现出色。然而，U-Net并未彻底解决全局信息建模的问题，其主要依赖于局部卷积操作，缺乏足够的全局上下文建模能力，这在处理复杂医学图像时，尤其是涉及多个病灶和复杂背景时，表现出了一定的局限性。此外，U形网络架构在处理复杂场景时，编码器难以充分捕获全局信息，而解码器在恢复高分辨率特征时也容易丢失细节。Transformer模型逐渐受到关注，并在医学图像分割领域中取得了进展，例如 TransUNet 将 Transformer 与 U-Net 结合，MedT 提出了基于门控轴向注意力的分割模型。尽管这些模型在全局信息建模方面取得了显著进展，但由于基于标准 ViT，输入尺寸固定，导致密集预测时计算成本高昂，且缺乏局部归纳偏置，使得在小规模数据集上难以有效训练。

为了克服这些局限性，最近提出了SAM2（Segment Anything Model 2），作为一种任务无关的分割模型，能够在自然图像和医学图像上执行通用的分割任务。目前已有一些基于SAM2的医学图像分割模型被提出，例如SAM2-UNet和MedSAM2，这些模型通过引入SAM2的分层编码器（Hiera），在多个医学图像分割任务中取得了良好的效果。Hiera模块逐层构建和提取不同尺度的特征，显著增强了全局特征提取能力。其多层次结构使SAM2在多尺度信息的整合和表达方面具有显著优势，能够更好地处理复杂的医学图像分割任务，尤其是在需要同时关注局部细节和全局上下文的情况下。Hiera的多层次结构使SAM2在多尺度信息的整合和表达方面具有显著优势，能够更好地处理复杂的医学图像分割任务，尤其是在需要同时关注局部细节和全局上下文的情况下。

尽管SAM2具备强大的特征提取和多尺度信息整合能力，但在处理复杂的医学图像时仍存在一些不足之处，尤其是在息肉分割任务中。息肉分割具有独特的挑战性，因为息肉通常表现为形态复杂、大小不一且边缘模糊的病灶，而背景组织的相似性进一步增加了分割的难度。为了应对这些挑战，我们提出了改进版的SAM2模型，命名为MSA-SAM2Net，以更好地适应医学图像分割中的特殊需求，尤其是针对息肉分割任务。MSA-SAM2Net通过结合多尺度大核注意力（LKSA）和边缘敏感注意力机制（EBM），显著增强了对边缘信息的捕捉能力和对不同尺度特征的表达能力。此外，我们在模型中集成了改进的残差特征块（MSA-RFB），有效提升了模型在处理细小病灶和复杂背景方面的表现。

MSA-SAM2Net在五个息肉分割数据集（Kvasir、ClinicDB、ColonDB、CVC-300 和 ETIS）上进行了评估，实验结果表明，MSA-SAM2Net在分割精度和鲁棒性方面均取得了显著提升，尤其是在处理复杂背景和边缘模糊的息肉时展现出优异的性能。

# 3 Method

## 1. Overview of MSA-SAM2Net

MSA-SAM2Net 是一种专为医学图像分割任务（尤其是息肉分割）设计的模型，结合了SAM2模型的优势，并引入了我们新提出的模块（包括GEAN）以提升模型的性能。该模型采用了改进的编码器-解码器架构，其中编码器部分结合了分层特征提取（Hiera）和全局-边缘注意力网络（GEAN），并通过MSA-RFB模块对编码器的输出进行特征提取，再传递给解码器部分，解码器部分使用传统的双卷积模块（DoubleConv）来恢复特征的空间分辨率。使用传统的双卷积模块（DoubleConv）来恢复特征的空间分辨率。整个架构旨在有效捕捉全局和局部特征，并提升边缘信息的提取能力，以应对复杂的医学图像分割挑战。

## 2. Encoder Design

### 2.1 Hiera Encoder

编码器部分采用了SAM2中的分层编码器（Hiera），以逐层提取和整合不同尺度的特征。Hiera模块通过多层次的特征提取，将图像表示为包含丰富上下文信息的特征图，从而在处理复杂的医学图像时表现出色。该模块能够有效捕捉全局信息并保持多尺度特征的完整性，使模型能够在多尺度的情况下更好地处理图像细节和全局关系。具体而言，给定输入图像 $I \in \mathbb{R}^{3 \times H \times W}$，其中 $H$ 表示高度，$W$ 表示宽度，Hiera 将输出四个层次特征：$X_i \in \mathbb{R}^{C_i \times \frac{H}{2^{i+1}} \times \frac{W}{2^{i+1}}} \quad (i \in \{1, 2, 3, 4\})$。对于 Hiera-L，$C_i$ 分别为 144、288、576 和 1152。

### 2.2 GEAN Module

#### 2.2.1 LKSA (Multi-scale Large Kernel Attention)

注意力机制能够迫使网络聚焦于关键信息并忽略无关信息。以往的模型采用了各种注意力机制，例如通道注意力（CA）和自注意力（SA），以获取更丰富的特征。然而，这些方法无法同时获取局部信息和长程依赖，并且通常仅在固定感受野上构建注意力图。受最新视觉注意力研究的启发，我们提出了多尺度大核注意力（LKSA），结合大核分解与多尺度学习来解决这些问题。模块通过不同尺度的大核卷积（如 3x3、5x5、7x7）来捕获图像的局部和全局特征，并结合卷积后的特征进行融合，从而提高模型对复杂特征的捕捉能力。

LKSA 的三个核心功能：

1. **大核注意力（LKA）**：用于建立特征之间的相互依赖关系。
2. **多尺度机制**：用于获取不同尺度上的异质相关性。
3. **门控聚合**：通过动态再校准实现灵活的特征融合。

**大核注意力：**

对于输入特征图 $X \in R^{C \times H \times W}$，大核注意力通过以下三部分构建长程关系：

- **深度卷积** $f_{DW}(\cdot)$：大小为 $(2d - 1) \times (2d - 1)$。其中d是膨胀系数
- **膨胀卷积** $f_{DWD}(\cdot)$：大小为 $\lceil K / d \rceil \times \lceil K / d \rceil$。其中K是卷积核大小
- **逐点卷积** $f_{PW}(\cdot)$：用于最后的特征融合。

公式为：

$$
LKA(X) = f_{PW} \left( f_{DWD} \left( f_{DW}(X) \right) \right)
$$
**多尺度机制：**

为了学习包含全尺度信息的注意力图，我们将固定的 LKA 与分组的多尺度机制结合。假设输入特征图 $X$ 被分成 $n$ 组 $X_1, X_2, ..., X_n$，每组特征的通道数为 $\frac{C}{n}$。对于每一组特征 $X_i$，通过 $\{K_i, d_i\}$ 分解的 LKA 构建局部与全局信息。

**门控聚合：**

为了避免因膨胀卷积带来的块效应，我们采用空间门控机制动态适配 LKA，可以自适应调整每个特征位置的权重，使之成为 LKSA：

$$
LKSA_i(X_i) = G_i(X_i) \otimes LKA_i(X_i)
$$

其中，$G_i(\cdot)$ 是由深度卷积生成的第 $i$ 个门控输出。



#### 2.2.2 EBM (Edge Boost Module)

EBM 模块的设计目的是通过卷积和梯度增强操作来强化输入特征图中的边缘信息。首先，模块使用自定义的 Sobel 算子来提取图像的水平和垂直梯度，以检测图像中的边缘特征。这些梯度特征经过激活和批量归一化后，与原始输入特征进行相加，从而整合原始特征与增强的边缘信息。

为了进一步提升边缘细节的捕捉能力，EBM 模块还包含两个卷积层：第一个卷积层用于提取更丰富的特征，同时保持输入特征的空间分辨率；第二个逐点卷积则用于精细调整特征的通道信息，并进行最终的特征融合。这一系列操作确保了模型在复杂背景和多变边缘情况下的分割性能。

通过将边缘信息有效地集成到特征图中，EBM 模块增强了分割网络在细粒度边缘细节上的表现，特别是在医学图像分割任务中，可以更好地处理那些具有复杂边缘特征的区域，例如病变边界模糊的息肉分割。该模块通过其简单而有效的设计，在保持计算效率的同时，显著提升了分割精度。



## 3. MSA-RFB

为了进一步提高模型对复杂特征的表达能力，MSA-SAM2Net的编码器部分还引入了改进的残差特征块（MSA-RFB）。MSA-RFB模块通过多尺度特征提取路径和全局特征融合来增强编码器的特征提取能力，它通过多尺度特征提取路径、全局特征融合和注意力机制，能够在复杂的背景中有效捕捉细粒度特征并增强模型对重要区域的关注度。

- **多尺度特征提取**：MSA-RFB模块使用多条卷积路径，每条路径采用不同大小的卷积核和扩张卷积，以实现对不同感受野的特征提取。
- **全局特征融合**：MSA-RFB模块包含一个全局池化分支，用于捕捉全局上下文信息，并通过融合这些特征来增强模型的整体表现。
- **注意力机制**：MSA-RFB模块还集成了通道注意力和空间注意力机制，用于提升模型在复杂背景下的分割性能，特别是在需要区分多个相似病灶的情况下。

**多尺度特征提取**

MSA-RFB 模块使用多条卷积路径，每条路径采用不同大小的卷积核和扩张卷积，以实现对不同感受野的特征提取。这些卷积路径包括三种不同的分支，每个分支的卷积核大小和扩张率不同，从而在空间上进行多尺度的特征学习。这种多样化的感受野设计能够有效捕捉到细节特征和全局上下文信息，有助于处理图像中包含的多种复杂结构。

**全局特征融合**

MSA-RFB 模块还包含一个全局特征提取分支，通过自适应全局池化对输入特征进行全局上下文信息捕捉。该全局特征随后被通过逐点卷积进行通道转换，并插值回原始空间尺寸，与多尺度分支的特征进行融合。这种融合方法不仅确保了对细节的关注，还增强了模型的全局特征表达能力。

**注意力机制**

为了提高模型对重要区域的响应能力，MSA-RFB 模块集成了通道注意力和空间注意力机制。通道注意力机制通过自适应加权的方式重新分配各个通道的重要性，从而使模型更加关注对分割任务有利的特征。而空间注意力机制则专注于对空间位置进行加权，使模型更容易关注到关键区域的像素点。通过结合这两种注意力机制，MSA-RFB 模块在复杂背景下的分割性能得到了显著提升。

通过 MSA-RFB 模块的引入，MSA-SAM2Net 能够更好地处理息肉分割任务中复杂的全局和局部特征，尤其是在需要区分多个相似病灶的情况下，实现了更高的分割精度和鲁棒性。

## 4. Decoder Design

解码器部分使用了经典的双卷积模块（DoubleConv）来恢复图像的空间分辨率。双卷积模块具有更简单的设计和较低的计算复杂度，但依然能够在保留细节信息的同时有效地进行特征重建。解码器通过逐步上采样特征图并结合编码器部分的跳跃连接，确保高分辨率特征得以充分利用，以恢复原始图像的分辨率并生成精确的分割结果。

## 5. Loss Function

在训练MSA-SAM2Net时，我们使用了加权 IoU 损失和二元交叉熵（BCE）损失的组合作为训练目标，具体公式如：
$$
L = L_{\text{wIoU}} + L_{\text{wBCE}}
$$
此外，我们对所有分割输出应用深度监督，MSA-SAM2Net 的总损失函数定义为：
$$
L_{\text{total}} = \sum_{i=1}^{3} L(G, S_i)
$$
加权 IoU 损失用于处理分割区域中的不平衡问题，BCE损失用于优化像素级分类的准确性。我们采用了Adam优化器，并通过学习率调度来动态调整学习率，以加快模型的收敛速度。

#  4 Experiments

## 4.1 Datasets

我们使用五个息肉分割数据集来评估模型的性能：**Kvasir**、**ClinicDB**、**ColonDB**、**CVC-300** 和 **ETIS**，如图1展示。每个数据集在样本数量、图像分辨率和息肉类型方面具有不同的特性，确保了全面的评估。这些数据集在息肉分割领域被广泛使用，有助于与现有方法进行公平对比。

图1.息肉分割数据集与划分

| Dataset      | Train Set | Test Set |
| ------------ | --------- | -------- |
| Kvasir-SEG   | 900       | 100      |
| CVC-ClinicDB | 550       | 62       |
| CVC-ColonDB  | -         | 380      |
| CVC-300      | -         | 60       |
| ETIS         | -         | 196      |

## 4.2  Implementation Details

在本节中，我们详细描述了模型的实现细节，包括硬件和软件环境、训练参数以及数据增强策略等。所有实验均在配备 NVIDIA GeForce RTX 3090 GPU（24GB 显存）上进行。模型使用 PyTorch（版本 2.4.0）实现，并在 Ubuntu 20.04 上训练。为了加速计算，使用了 CUDA 12.1 和 cuDNN。此外，我们使用的是 SAM2 的 Hiera-L 版本 作为编码器部分。

我们使用 AdamW 优化器训练模型，初始学习率为 1e-3，权重衰减为 5e-4。学习率调度策略采用 Cosine Annealing 调度器，最小学习率为 1e-7。所有输入图像均调整为 352×352 的尺寸，批量大小为 12。模型训练 20 个 epoch，批量大小为 12。训练目标为 结构化损失函数，包含 加权 IoU 损失和二元交叉熵（BCE）损失，以解决息肉分割中的类别不平衡问题。

在训练过程中，模型使用了三层分辨率输出（pred0、pred1、pred2），每层均计算损失，最终损失为三者之和。为了增强模型的泛化能力，我们在数据增强方面采用了随机垂直和水平翻转两种策略。

## 4.3 Comparison with the State-of-the-Art Methods

为了验证我们提出的 MSA-SAM2Net 的有效性，我们将其与多种当前最先进的息肉分割模型进行了对比，包括 PraNet、SANet、CaraNet、CFA-Net 和 SAM2-UNet。在五个常用的数据集上，我们分别使用 mDice 和 mIoU 作为评估指标。

实验结果如表1所示，MSA-SAM2Net 在所有数据集上均表现出优异的性能，尤其在 Kvasir、ColonDB 和 ETIS 数据集上显著优于其他模型。在 Kvasir 数据集上，MSA-SAM2Net 的 mDice 达到了 0.925，mIoU 为 0.878，均优于其他模型。在 ColonDB 数据集上，我们的模型 mDice 和 mIoU 分别为 0.810 和 0.736，相比于其他模型取得了较大的提升。

此外，MSA-SAM2Net 在 ETIS 数据集上也展现了强大的分割能力，mDice 和 mIoU 分别达到了 0.788 和 0.711，表现优于其他对比方法。相比于同样使用 SAM2 的 Hiera 作为主干的 SAM2-UNet，MSA-SAM2Net 在所有数据集上的性能均有提升，表明我们提出的模块在捕捉多尺度特征和边缘信息方面具有显著优势。

表1. 不同方法在五个息肉分割数据集上的性能对比（mDice / mIoU）

## 4.4 Ablation Study

在本节中，我们对模型进行了广泛的消融实验，以验证 GEAN 模块和 MSA-RFB 模块对模型性能的贡献。

### Ablation on GEAN

为了验证 GEAN 模块对模型性能的贡献，我们在 **CVC-300**、**CVC-ClinicDB**、**CVC-ColonDB**、**ETIS-LARIBPOLYPDB** 和 **Kvasir** 数据集上进行了消融实验。在去除 GEAN 模块后，模型在所有数据集上的性能均有所下降，具体表现为 mDice 和 mIoU 指标的下降。如表2所示，加入 GEAN 模块后与 **SAM2-UNet** 相比，mDice 和 mIoU 指标在 **CVC-300** 数据集上分别提高了 **0.9%** 和 **1.3%**，在 **CVC-ClinicDB** 数据集上分别提高了 **2.1%** 和 **2.8%**。这表明 GEAN 模块在捕捉复杂上下文和增强边缘信息方面的有效性。

### Ablation on MSA-RFB

我们还对 **MSA-RFB** 模块进行了消融实验，验证其对模型性能的贡献。在 **CVC-300** 数据集上，去除 **MSA-RFB** 模块的模型 mDice 和 mIoU 指标下降至 **89.6%** 和 **83.2%**。类似地，在 **CVC-ClinicDB** 和 **Kvasir** 数据集上，去除 MSA-RFB 模块后模型的 mDice 和 mIoU 也有所下降。这些结果表明，**MSA-RFB** 在增强多尺度特征提取和捕捉全局上下文信息方面发挥了重要作用。

**表2. 消融实验结果（mDice / mIoU）**

在结合 **GEAN** 和 **MSA-RFB** 模块的情况下，**SAM2-UNet+GEAN+MSA-RFB** 在所有数据集上均取得了最佳性能。特别是在 **Kvasir** 数据集上，mDice 和 mIoU 分别达到了 **92.5%** 和 **87.8%**，显著优于基线模型 **SAM2-UNet**。这些结果验证了 GEAN 和 MSA-RFB 的协同作用可以有效提升息肉分割的准确性和鲁棒性。



# Conclusion

